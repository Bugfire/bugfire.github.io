{"2017/03/11/InstallHexoAndThemes":"ふと思い立って、Github pages を使って Blog を作ってみた。\n環境は何でもよかったが、nodejs ベースの [Hexo](https://hexo.io/) を使ってみることにしました。\n\n# nvm/nodejs のインストール\n\nすでにインストールされていたnodejsが0.12だったので、ついでにnvmをインストール。\n\n```sh\n$ git clone git://github.com/creationix/nvm.git ~/.nvm\n```\n\n.profile に1行追加\n```sh\n$ echo 'if [[ -s ~/.nvm/nvm.sh ]] ; then source ~/.nvm/nvm.sh ; fi' >> ~/.bash_profile \n$ source ~/.bash_profile \n```\n\nバージョンは適当に選択\n```sh\n$ nvm --version\n0.33.1\n$ nvm ls-remote\n(いっぱい)\n$ nvm install v5.12.0\n$ node --version\nv5.12.0\n```\n\n# Hexo のインストール\n```sh\nnpm install --save hexo\n```\n\n## Blog の作成\n```sh\n$ ./node\\_modules/hexo/bin/hexo init blog\n$ cd blog\n$ npm install\n```\n\n## Theme の fork\n一応。github から landscape を fork しておく。\n\n## Theme の submodule 化\n```sh\n$ cd themes/\n$ git submodule add https://github.com/bugfire/hexo-theme-landscape.git landscape\n```\n","2017/03/17/AssetBundleCompress1":"# 目的\n\nAssetBundleはLZMAやLZ4で圧縮されますが、扱うデータの特性がわかっている場合はより特殊化した\n圧縮が期待できるのではないかと考えました。\n\n例えば目パチのようなアニメーションの画像データでは以下のようなアプローチがあります。\n\n- 目だけを上書きする透過画像を生成して上に乗せる。\n  透過面積が多い画像であれば標準のSpritePackerや [TexturePacker](https://www.codeandweb.com/texturepacker) で効率的なAtlas化が可能です。\n- 差分画像を生成する。例えば [宴](http://madnesslabo.net/utage/) のダイシング機能。\n\nしかし、今回は制約があり上の手法は使いません。\n\n# 前提\n\n制約は以下の通りです。\n\n- 使う側で特別なコードは一切書きたくない。\n- TextureでありSpriteではない。\n- 機種依存圧縮(PVRTC, ETC)を使いたい。\n- 透過なしで1パスで描画を行いたい。\n\nPVRTC, ETC のバイト列を生成し、Unity の Texture としてロードができればよいのですが、\nちょっとわからなかったので別の方法を試します。(\\*1)\n\n# 手法\n\nAssetBundle をただ圧縮し、インストール時に展開するというアプローチを試してみます。\n\nテクスチャ圧縮はGPUの機能的制約から固定長で同じサイズのテクスチャであれば、同じ座標のデータは\n同じブロックに存在します。したがって、局所性が高く、同一のピクセル構成部分であれば、同一のバイナリ構成になる可能性が高いと予想されます。\n(PVRTC は近辺のブロックも参照を行うので、影響範囲は少し大きめになりますが、距離に応じて影響は低くなります)\n\n(\\*1) のPVRTCからテクスチャ生成ができれば、AssetBundle 内で圧縮するアプローチを取ることができるのですが、Nativeでテクスチャを生成する以外の方法があれば、誰か教えてください...。\n\n# 問題点\n\n- 圧縮前はロスレス画像でなければならない。\n  見た目が同じでもLossyな圧縮を行なった結果、微妙に画像データが異なると困ります。\n- ストレージでの消費容量は無圧縮なので比較的大きい。\n- 複数のバリエーションをロードするとGPU側のメモリ消費は多い。\n- 暗号化を行えない。暗号化を先に行うと圧縮が難しい。\n  圧縮してから暗号化だと、ストレージでは圧縮を展開したデータになるため暗号化がかかっていない状態になります。\n\n[(2)](/2017/03/17/AssetBundleCompress2)へ続く。\n","2017/03/17/AssetBundleCompress2":"# 実験\n\nデータはUnityChanをベースに、ImageMagickでAlphaチャネルを削除しました。\n```bash\n$ convert portrait_kohaku_02.png -background black -alpha remove portrait_kohaku_02a.png\n$ convert portrait_kohaku_01.png -background black -alpha remove portrait_kohaku_02b.png\n```\n\n画像サイズは2524x3189ですが、2048x2048, MipMap なしとして取り込みました。\nPVRTC/ETC1の4bppを使用で、2048x2048x4/8が2枚で4MBとなります。\n\n# スクリプト\n\nAssetBundle は以下の簡単なスクリプトで生成\n```cs\nusing System.Collections;\nusing System.Collections.Generic;\nusing UnityEngine;\nusing UnityEditor;\n\npublic static class AssetBundleCompressTest\n{\n    static string[] _assetNames = new string[2] {\n        \"Assets/AssetBundleTest/UnityChan/portrait_kohaku_01a.png\",\n        \"Assets/AssetBundleTest/UnityChan/portrait_kohaku_02a.png\",\n    };\n\n    static AssetBundleBuild[] CreateBuildMap (string mode, BuildTarget target)\n    {\n        AssetBundleBuild[] buildMap = new AssetBundleBuild[1];\n        buildMap [0].assetBundleName = string.Format (\"Test_{0}_{1}.unity3d\", mode, target);\n        buildMap [0].assetNames = _assetNames;\n        return buildMap;\n    }\n\n    [MenuItem (\"AssetBundlesCompress/RunTest\")]\n    static void BuildAssetBundles ()\n    {\n        var outputPath = \"AssetBundles\";\n\n        System.IO.Directory.CreateDirectory (outputPath);\n\n        //BuildTarget.Android,\n        //BuildTarget.iOS,\n        var target = EditorUserBuildSettings.activeBuildTarget;\n        BuildPipeline.BuildAssetBundles (\n            outputPath: outputPath,\n            builds: CreateBuildMap (\"RAW\", target),\n            assetBundleOptions: BuildAssetBundleOptions.UncompressedAssetBundle,\n            targetPlatform: target);\n        BuildPipeline.BuildAssetBundles (\n            outputPath: outputPath,\n            builds: CreateBuildMap (\"LZ4\", target),\n            assetBundleOptions: BuildAssetBundleOptions.ChunkBasedCompression,\n            targetPlatform: target);\n        BuildPipeline.BuildAssetBundles (\n            outputPath: outputPath,\n            builds: CreateBuildMap (\"LZMA\", target),\n            assetBundleOptions: BuildAssetBundleOptions.None,\n            targetPlatform: target);\n    }\n}\n```\n\n# 結果\n\n|方法|サイズ|\n|----|------|\n| RAW | 4198973 |\n| LZ4 | 876341 |\n| LZMA | 609787 |\n\n2x2048x2048x4/8は4194304なので、(4198973 - 4194304) = 4669byteがヘッダ等メタデータとなりますね。\n\nアーカイブの中身を見た感じ、未圧縮の形式では、ファイルの前にかならず、（文字列長) + (ファイル名)が、\n入るようなので、ここをファイルの区切りとして圧縮を試して見ます。\n\n[(3)](/2017/03/19/AssetBundleCompress3)へ続く。\n","2017/03/19/AssetBundleCompress3":"# 圧縮の方針\n\n仮定\n- アーカイブ内に存在するファイルの内容は、同一オフセットには同一のデータが入ることが多い。\n\n# 実装\n\nアーカイブ全体からファイル名部分を検索するのには、有名な Boyer-Moore String Search アルゴリズムを使います。\nwiki にソースすらあるので、それを参考にしても良いですが、今回は StackOverflow の記事から使用させていただきました。\n\n参考:[Search longest pattern in byte array in C#](http://stackoverflow.com/questions/9889427/search-longest-pattern-in-byte-array-in-c-sharp/9890164#9890164)\n\nファイル名で区切られた領域をブロックとみなし、ファイル中の全ブロックと全ブロックを比べ、同じオフセットで同じデータ\nが入る部分を抽出し、出力は、データブロックと参照ブロックが並ぶ構成にしました。頭の悪い辞書圧縮という感じです。\n\n正確にデータ部分が抽出できれば、PVRTC/ETC1ともに8byteが1blockなので、それを利用して、オフセットによらず圧縮テクスチャ特化型辞書圧縮もできそうですが、手間をかけない方針なのでやりません。\n\n参考:[Disunity on github](https://github.com/ata4/disunity)\n\n# 結果\n\n|方法|サイズ|\n|----|------|\n| RAW | 4198973 |\n| LZ4 | 876341 |\n| LZMA | 609787 |\n| 圧縮 | 2381911 |\n\n大部分が同じデータなのでだいたい半分にはなりましたが、通常の圧縮をしていないのでまだまだ大きいですね。\n\n[(4)](/2017/03/19/AssetBundleCompress4)へ続く。\n","2017/03/19/AssetBundleCompress4":"# 圧縮\n\n下段として通常の圧縮を試してみます。その前に、先人の知恵を見て見ましょう。\n\n参考:[.NET Compression Libraries Benchmark](https://ianqvist.blogspot.jp/2014/12/net-compression-libraries-benchmark.html)\n\n何も考えずに.NETのDeflateと、性能が良さそうなLZMAを試して見ることにします。\n\nLZMAはPublicDomainの7Zip SDKを使用します。\n\n# 結果\n\n|方法|サイズ|\n|----|------|\n| RAW | 4198973 |\n| LZ4 | 876341 |\n| LZMA | 609787 |\n| 圧縮 | 2381911 |\n| 二段圧縮(.NET) | 409940 |\n| 二段圧縮(LZMA) | 318962 |\n\nようやく、素のLZMAの半分くらいになりました。DeflateとLZMAは、速度とサイズのトレードオフでしょうか。\n\nサンプルソースは、 [https://github.com/Bugfire/test_assetbundlecompress](https://github.com/Bugfire/test_assetbundlecompress) に置いておきました。\n\n# 追記\n\n[2016年のOSS圧縮ツール選択カタログ](https://qiita.com/nishemon/items/818cc64dc2f8577edd87) を読んだら、zstdのC#版が欲しくなってきました。native wrapperは存在しましたが、なんとなく。\n","2017/05/06/QnapFfmpeg":"家で家族の動画を共有している QNAP / DLNA が最近動いていないのでメンテをしました。\n\n- TwonkyServer がメンテされていないみたいなので、標準の DLNA Server に置き換えました。\n- PS4 から見に行くと反応が遅いですが、一応動いていますね。\n- もともと、MTS がうまく再生できていなかったのは、やっぱりうまくいかない。\n- トランスコード設定をしてみるが、やっぱりうまくいかない。\n- ログをみると変換に失敗しているようだ。\n\n昔は、自分で QNAP 上で ffmpeg を実行して再生可能にしていたので、思い出しつつ実行してみる。  \n\n- 過去のスクリプトではやっぱりうまくいかない。\n- コマンドラインオプションが違うようだ。ffmpeg のバージョンが違うかな？\n- ググってみると複数の ffmpeg が入っているようだ。確かに。\n- 新しい方でもやっぱりこける。ググってみるとライセンス上の問題で AC3 を外しているようだ。\n\nしょうがないので自前ビルドしてみる。\n\n- ipkg がない...。これも紆余曲折あって App Center から入らないようだ。\n- [こちらから](https://github.com/Entware-ng/Entware-ng/wiki/Install-on-QNAP-NAS)インストール\n- ```/opt/bin/opkg install ffmpeg```\n\nなんとか動作。\n","2017/05/16/RayProfiler":"簡単なデバッグ用スクリーンインジケータを作りました。\nゲーム開発でよく見る奴です。\n\n車輪の再発明というか、標準の Profiler でよくね？と思いますが、私もだいたい同意です。\n\n![RayProfiler](/blogdata/images/RayProfiler.png \"RayProfiler\")\n\n- 上の白い四角がTargetFPSの範囲になります。グラフがはみ出すのは処理が間に合っていないときです。\n- 赤がRender、グレーは1フレームの時間です。Editor 上のスクリーンショットなので TargetFPS とグレーが一致していませんね。\nPhysics, Update, LateUpdate, Animation 等の処理別に処理時間を計測していますが、Render 以外は目立ちません。\n- 下が過去60フレームの1フレームの処理時間/1フレームの時間のグラフです。\n- GCがあったフレームはグラフ上で赤/黄で目立つように表現されます。\n\n## 特徴\n- リリースビルドでも動く(むしろ、止めたければどうにかいじってください)\n- 動的なメモリ割り当て無し(例外あり、後述)\n- スクリーンに描画を行うので、実機で確認可能\n\n## 動的なメモリ割り当てなし\nプロファイル、描画等で動的なメモリ割り当ては行なっていません。固定バッファでやりくりしています。\n\n例外は、 `yield WaitForEndOfFrame` を行なっている部分で、Unity側の `MoveNext ()` で毎フレーム16byte確保されます。\n誰か防ぐ方法教えてください。\n\n## RayString\n低機能なStringモドキです。使い方は例を見ればわかると思います。\n```\nvar r = new RayString(100);\nr.AddStr (\"Foo\").AddInt (10).AddStr (\"Bar\").AddFloat (0.5f, 0, 1);\nAssert.AreEqual(r.ToString (), \"Foo10Bar0.5\");\n```\n上の例では、`ToString ()`でnew stringされていますが、`char[] Buffer`を参照することで動的メモリ割り当て無しで中身が取り出せます。\n\n実装上の都合で(floatの内部表現が面倒なので)、AddFloat の精度は低いです。float の持つ精度を超える小数部の桁数を指定した場合、\nC# のライブラリでは0でフィルされますが、このAPIでは精度以上の部分はゴミが入ります。\n\nバッファが溢れそうなときは拡張を行うので、このときは動的メモリ割り当てを行います。\n\n## RayCanvas\nデバッグ用簡易Canvasです。文字列と矩形しか表示しません。\nMesh 用のデータを静的に持っておくことで、動的割り当てを回避する実装になっています。\nデータサイズは静的になりますが、表示内容が少なくても多くてもメモリ消費も描画コストもかかります。\n\n## 参照\nパッケージとソースは[github](https://github.com/Bugfire/snippets/tree/master/unity/RayStorm)にあります。\n\nUnity5.3, 5.4, 5.5. 5,6でパッケージを作りましたが(疲れました)、ソースは同一です。サンプルprefabをそれぞれのバージョンで生成しただけです。\n","2017/10/08/diskchecker":"ドライブレコーダー用にMicroSDを何枚か買いました。SDカード系って偽物とかありますよね。自分は信頼できる店でしか買わないのでひっかかったこととかないつもりですが...。\n\nチェックするツールもWindows用でいくつか検索で見つけることができますが、色々と面倒なので低機能なものを作ってみました。\n\n- node.jsで200行未満\n- ディスクが一杯になるまで指定ディレクトリに再現可能な乱数系列の256MBのファイルを作成し続ける\n- ディスクが一杯になったら、作成したファイルを検証する\n- ついでに読み込み・書き込み速度を測る\n\n低レベルで検査しているわけではないので、全エリアはチェックしていません(256MB未満の残り領域、アライメント部分、ディレクトリ情報等)。デバイスファイルを使えばできますが、オペミス怖いしそこまでやらなくてもいいと思いましたのでこのような実装にしました。\n\n[https://github.com/Bugfire/diskchecker.git](https://github.com/Bugfire/diskchecker.git) にあります。\n\n","2018/03/19/WakeOnLan":"PC を定期的に起動・終了したく、試しました。\n\n## 指定時間で停止\n\n```bash\n$ sudo crontab -e\nMM HH * * * /sbin/shutdown -h now\n```\n\nまあ、普通ですね。歴史的に(?) localtime での時間設定らしいので、気をつける。\n\n起動時にしか localtime をチェックしないので、起動後に localtime を変更する場合は、 cron を再起動しておく。\n\n```\nsudo service cron restart\n```\n\n## 指定時間で起動\n\nWake On Lan の magic packet を投げる方法はいくつもあると思いますが、nodejs に慣れているのでそれを選びます。\n\n### 依存ライブラリのインストール\n\n```bash\nnpm init\nnpm install --local --save wake_on_lan cron forever\n```\n\n- wake\\_on\\_lan 名前通り\n- cron 時間で指定して実行\n- forever おてがるデーモン化\n\n### テスト\n\nひとまず実行してみる。\n\n```javascript\nconst wol = require('wake_on_lan');\nwol.wake('xx:xx:xx:xx:xx:xx');\n```\n\n起動する。楽だ。LAN が複数ポートある場合は、一つ目にしか飛ばないのか起動しなかったのでオプションをつける。\n\n```javascript\nwol.wake(mac, { address : '192.168.xx.255' });\n```\n\n動かない場合は `sudo tcpdump -nX udp and port 9` 等で対象と同じネットワークから見てみる。\n\n### 結果\n\n最終的には、設定を外出ししてこんな感じに。\n\nソースファイル\n```javascript:wol.js\n'use strict';\n\nconst wol = require('wake_on_lan');\nconst config = require('./config.js');\n\nfunction kick() {\n    config.hosts.forEach(host => {\n        wol.wake(host, config.wol);\n    });\n};\n\nconst CronJob = require('cron').CronJob;\nnew CronJob(config.schedule, kick, null, true, config.timezone);\n```\n\n\n\n設定ファイル\n```javascript:config.js\nmodule.exports = {\n    timezone : 'Asia/Tokyo',\n    schedule : 'MM HH * * *',\n    hosts : [\n        'xx:xx:xx:xx:xx:xx',\n    ],\n    wol : {\n        address : '192.168.xx.255',\n        num_packets : 10,\n        interval : 500,\n    },\n};\n```\n\n### デーモン化\n\n- 起動 `./node_modules/forever/bin/forever start ./wol.js`\n- 終了 `./node_modules/forever/bin/forever stop ./wol.js`\n- 確認 `./node_modules/forever/bin/forever list`\n\n長いパスが嫌な子はパスを通すか wrapper を作るか、global にインストールなぞ。\n\n## 参照\n\n多少コードは違いますが、ソースは[github](https://github.com/Bugfire/wake_on_lan.git)にもあります。\nこちらはDockerhubでビルドもしていてコンテナ用になっています。\n","2019/02/28/VRMViewer1":"ロボスタの勉強会に出席してみて、VRM(というかUniVRM)は気軽だな、と再認識したので試してみた。\n\nせっかくなので、WebGL ビルドで。\n\nhttps://bugfire.dev/VRMViewer/index.html\n","2019/09/27/React":"## SPA\n\n長いお休みをいただいているので、練習がてら、このサイト(Bugfire.dev)を React で SPA/PWA 化しました。\n\nPage は gh-pages でホストをして、Blog は Markdown にして、index と記事を json でホストして取りに行くようにしました。\n\nRedux/Flux 的なことは Unity や Vue.js で少しかじりましたが、今回は端折りました。\nというか色々端折っても三日かかりました、難しい。\n\n### TODO\n\n- [x] Year/Month/Tag で絞り込むUI\n- [ ] Android でアイコンが丸くならない、困った。\n\n  \"purpose\": \"maskable\" で良いとの記事を見たが動かない。\n  十分透過な画像を食わせると良いとは読んだけど、それやると iOS が変になりそう。\n- [x] Markdown (Code highlight)\n- [x] atom.xml\n- [x] sitemap.xml\n\n### 10/1 追記\n\nPWA は色々おかしい(難しい)ので serviceWorker を止めました。MarkDown も single back-quote が div 要素になったり、普通に hatena blog や qiita にかけば良いのでは？、と頭をよぎってしまうので、あまり時間をかけないようにしたい(自戒)。\n\n自分のためのコードを書くのは楽しいですけどね。\n","2019/09/30/DockerComposeOnQnap":"## ContainerStation\n\nQNAP の ContainerStation をとても便利に使っていたのですが、Deploy のたびに設定 (UIからVolume等) をしたりとか、複数の Container が協調するのがめんどいというか、DockerCompose したいよなあ、と思って VPS を借りてみたりしましてました。\n\nところが、DockerCompose 対応してる、ということに、最近ようやく気が付きました(最初からあった?)。\n\n## DockerCompose == APP\n\nQNAP 用語的には、docker-compose は **APP** ということみたいです。\n\nDocker 社の作っている app plugin とは別物っぽいです。\n\n**APP** は二通りの作成方法があるようです。\n\n- ライブラリ(初期設定なら https://github.com/qnap-dev/container-apps/tree/2.0) をつかう\n  templte/*/wizard でメニュー設定と、docker-compose.yml の項目への binding が定義できるようだ。\n- 自分で設定する(**作成**の所の**アプリケーションの作成ボタン**から docker-compose.yml を編集して追加できます)\n  docker-compose.yml に即値で書いていく。\n\n自分は後者を使いました。設定項目が全て手の中にあるのでバックアップ・履歴管理も楽だし。(docker-compose.qnap.yml で commit しています、詳細な設定・秘密情報は Volume に置く方針です)\n\n注意としては、build エントリがあると失敗するので、消しておきます。なければ image を自動的にダウンロードして実行します。\n\n## image の更新\n\nなお、概要タブの Container/APP 一覧から、編集ボタンを押すと既存の **APP** の yml の編集ができ、**適用** すると自動的に更新されます。\n\ntag を :latest にした場合は **適用** を実行したところで、既存の latest を更新してくれないので、image を削除する必要があります。参照されていると削除できないので、面倒です。普通に versioning しましょう。\n","2019/09/30/Qnap20190930":"家で動かしている QNAP を色々更新していました。\n\n## Refactoring\n\nQNAP 屋内サービスのコード・構成のリファクタリング\n\n- docker-compose を使うように変更\n- docker-compose で syslog に投げる\n- JavaScript で作ったものを TypeScript にリファクタリング\n- npm package の update, http から axios への書き換え\n- Dockerfile で マルチステージビルドを使って image の削減\n- TypeScript で共通処理部分を切り出し\n\nみたいなことをしていました。\n\n## Pi2B to Nature Remo\n\n今まで、特に意味もなく Raspberry Pi 2B の USB 温度計で部屋の温度をとって DB に放り込んでいました。それを今回 NAS 側に移しました。\n\n温度取得を QNAP の Docker + Nature Remo の方の API に切り替えた結果、湿度と照度を追加で取得できるようになりました。\n\n地味に unbound が動いていた (dns blacklist を作っていた) のに気が付いていなくて、突然名前が引けなくなって、急遽ルーターの設定を変更。\n\nuptime が 1000 日以上だったので、トラブルもなく安定してよく動いていたな、と思いました。(Security update は置いておいて)\n\n## hardware EOL and new device\n\n過去の構成は:\n\n- TS-259Pro - Surveillance Station & DB & Backup\n- TS-651 - Docker & FileSharing\n\n購入してから6年くらいの TS-269Pro の EOL が近づいて来ていたので、TS-453Be を購入しました。新構成は:\n\n- TS-651 - Surveillance Station & DB & Backup\n- TS-453Be - Docker & FileSharing\n\nTS-453Be を SSDx2 の構成にしたら、11~13W くらいの電力消費におちつきました。CPU を全然回していないとはいえ、最高ですね?\n\nTS-651 は SSDx2 HDDx2 で 37W くらいです。SSDで電気代が月500円安くなったとして、5年で3万円、過去の書き込みレートだと 60G/day くらいだったので、1年で21TBW、5年なら100TBW、TBW的にはいけそうですが、まだまだ容量単価がつらい。\n(TimeMachine 等の Backup も兼ねているので、あまり容量を削れない)\n\nSurveillance Station の課金が別 NAS に移行できないので、QVR Pro を試しているのですが重いねコレ...。\n\n## メモリー追加\n\nついでに、両方ともメモリーを 16G にしました。Container も Surveillance もメモリ喰いですし。\n\nメモリーはだいすきな SanMax の DDR3L-1866 の 8Gx2 です。もちろん QNAP での動作保証はありません。\n\n  [SanMax (サンマックス)\nSMD-N16G28CTP-18ML-D-BK](https://www.ark-pc.co.jp/i/11702376/)\n\nよくセールになっていますね。\n\n## 10GbE\n\n去年末に購入した MacMini の 10GbE が一度も使われていないので、Hub 共々買い揃えたいと思いつつもまだ高いし、消費電力凄そうで躊躇してます。\n","2019/10/04/ContainerStationApi":"Container Station (QNAP) に Web API あるのですね。\n本当、知らないことだらけです。\n\nhttp://qnap-dev.github.io/container-station-api/system.html\n\nlogin して session cookie をもらう形式(かつexpireが短い)なので、admin の ID/pass をシリアライズする必要はありますが、terraform 化できそうな感じですね\n\nGolang の勉強がてら作り始めた Container Station の状態表示 CLI\n\nhttps://github.com/Bugfire/qnapcc\n\nGolang は初めて書くのでいろいろおかしいかもしれません。\n","2019/11/12/SpaOnGithubPages":"## SPA化\n\n標題そのものは各所のドキュメントで問題なく行えました。\n\nblog は Markdown を json でまとめて、SPA 側で html にレンダリングしています。しかし、めんどい。\n\n## Google Search Index\n\n### atom.xml\n\nblog 部分は、md から json 化して index を作っているので、index を作るときについでに atom.xml を作成。\n\n### sitemap.xml\n\n面倒なので、SPA を自前 crawler で適当になめて sitemap.xml を作成。puppeteer とても良い。\n\nhttps://github.com/Bugfire/create_sitemap に自分用の設定で適当に置いてあります。\n\n### Hash based router\n\n最初は Hash based router (*http://foobar.com/#/hoge/foo* みたいなやつ)を使っていましたが、Hash だけ別の場合は Google 様は同じ URL とみなすので、全ページ同じ URL となり index されませんでした。\n\n### Push state router\n\nしょうがないので普通の router を使う。\n\n#### 1. 404 に index.html を置く\n\n404.html に index.html をおいたら、全てのアクセスが一個のファイルで動くじゃん俺天才、と思ってやってみましたが、動作は\nしましたが、status 404 の場合は一切 index されないという悲しい結果に。\n\n#### 2. 404 から index.html?url 経由で開く\n\nちょっと調べた感じでは、これでいけるとありましたが、自分は index されませんでした。\n\n#### 3. あらゆる全ての箇所に index.html を置く\n\n大変bakaです。sitemap に存在する全ての URL に index.html をコピー。いいんです、index.html はたったの 2616 バイトなんです。sitemap がとても役に立った、いやっほ!?\n\n#### 4. おまけ\n\nGithub Pages は、  \n*http://foobar.com/XXX/YYY* => *XXX/YYY.html*  \n*http://foobar.com/XXX/YYY/* => *XXX/YYY/index.html*  \nと区別をしよう！\n","2019/12/20/AdventCalendar2019":"アドベントカレンダーで書いた記事 [多脚戦車に乗ろう](https://qiita.com/bugfire/items/0bc7f7874e0f9e346a91) についての日記です。\n\n## 11/17(日) 秋葉原\n\n娘がキッザニアに行っている間に、一人で秋葉原行ったわけです。\n\n秋葉原散策中に娘がキッザニアのお土産コーナーで[とげまる](https://www.elekit.co.jp/product/MR-9108)と[フォロ](https://www.elekit.co.jp/product/MR-9107)を迷っていたと聞いて、自分でもサイトで見てみたら、何これカッコいい、自分も欲しい！  \nそれで、ツクモロボット王国にフォロを買いにいったのでした。\n\nフォロは売っていなくて、売り場にあったVR220カメラをラズパイzeroと合わせて買ってしまったのです。衝動買いってやつです。時雨堂の V (@voluntas) さんのツイートでラズパイで WebRTC 楽勝っていう記憶が勝因でした。\n\nちなみに娘は、迷った末に**とげまる**にしていました。家でビックカメラ通販にフォロを発注しました。\n\n## 11/18(月) 実装1日目\n\n仕事が終わった後の夜中にOSをインストールしたり、ピンヘッダをハンマーで打ち込んだり。  \nWebRTC/momo は簡単に sample ページを表示できてうひょーってなる。\n\n## 11/19(火)\n\nスイッチサイエンスに部品を色々発注。作業はなし。\n\n## 11/20(水) 実装2日目\n\nビックカメラから在庫ないから取り寄せってメールがきて、カッとなってヨドバシ通販に発注。  \n夜中に WebGL/three.js を使って球面表示もさっくりと。便利な世の中ね。\n\n## 11/21(木)\n\nスイッチサイエンスの部品が届いた。\n\n## 11/22(金)\n\nフォロが届いた。\n\n## 11/23(土) 組み立て\n\nフォロを組み立てる、かわいい。\n\n## 11/24(月)\n\n夜中にフォロとモータードライバー、繋ごうとしたらピッチの問題でつながらない。  \n半田する気合もなく、amazon に発注して放置。\n\n## 11/26(水) 実装3日目\n\nビックカメラのフォロが届く。こちらは娘に。\n\namazon の荷物が届いたので、やはり夜中にヒャッホーってモーター周りを実装。  \ntwitter に動画を投稿したの初めてだよ。\n\n## 11/28(金)\n\n社内で Advent Calendar の記事書く人を募集していたので、ちょうどやっていたこれを書くことに。  \n転職したてで、これといって書けることがなかったので助かりました。\n\n## 12/3(火) 半田付け\n\n半田でケーブルを最小限の長さで作り直した。\n\n## 12/7(土)\n\n12月1~3日に記事を書きあげて、無事に記事公開。  \n社内のみなさん力強い記事書いていてスゴイ。\n\n## おまけ\n\n調子に乗って RaspberryPi 4B+ と Jetson nano を購入して手元にありますが、12/7 に発注した 4k 球面USB カメラはまだ到着しておりません。\n","2019/12/21/GDM39":"とてつもなく感動したので記録を取っておく。\n\n## 序\n\n2019/12/20 にヒカリエで DeNA 主宰のエンジニア向け勉強会に出席しました。\n\n* ref. [サーバー\"コード\"レスアーキテクチャによるゲームクライアント開発 の前置き](https://engineer.dena.com/posts/2019.12/server-code-less-architecture-in-mobile-game-client/)\n* ref. [新ゲームサーバ基盤TakashoでのGo言語活用事例の紹介](https://speakerdeck.com/kyotak/xin-kemusahaji-pan-takashotefalsegoyan-yu-huo-yong-shi-li-falseshao-jie)\n\n## サーバー“コード”レスアーキテクチャ、とは\n\n自分の雑な理解では\n\n* クライアントはサーバーにバイナリデータ(以下DAO)としてデータを保存する、DAOはC#の一定の形式のクラスを便利SDKで保存できる\n* サーバーは基本的にデータの中身は感知しない、1APIを1トランザクションとする Key-Value ストア\n* サーバーは、ガチャ・課金等、重要な要素ではサーバ側マスターデータで定義された抽象的なトークンをルールに基づいて発行するが、トークンのDAOへのマッピングは感知しない\n* クライアントは上のトークンをDAOへと変換するトランザクションをもって消費する、APIとしては冪等性がある\n* 汎用的な改竄対策がクライアント・通信共にある\n* 別途プレイヤのバイナリデータをJSON等でエクスポートしてDWHに流して非同期に分析するパスはある\n* 汎用的なサーバAPI実装と、ゲーム固有のAPI実装の両方があるが、前者だけでも最低限は成立する\n\n## シーケンス的なもの\n\n### 伝統的実装\n\n![Traditional](/blogdata/images/Traditional.svg \"Traditional\")\n\nロジックはサーバー側だけにあり、APIを投げて結果を受け取るという、伝統的な実装です。\n常に通信結果を待つので、通信環境次第ではストレスになり得ます。\n\n### 一部非同期実装\n\n![SyncAsync](/blogdata/images/SyncAsync.svg \"SyncAsync\")\n\nロジックはサーバーとクライアントにあり、一部の結果が完全に予測できるAPIのみは同時に実行することで、レスポンスをよくしようとする実装です。  \nサーバーとクライアントに同じロジックを載せるので辛い。\n\nどこかで、こういう実装をしていた気がします。\n\n### サーバー“コード”レスアーキテクチャ\n\n![ServerCodeLess](/blogdata/images/ServerCodeLess.svg \"ServerCodeLess\")\n\nロジックはクライアントにのみもち、サーバーではロジックを実行しません。ガチャの部分はややこしく見えますが、サーバーではダイスだけを振り、DB(DAO)への反映ロジックは全てクライアントの仕事になります。\n\n一目見て、チート大丈夫？って感想を持つと思いますが、DAOの中身を非同期に監査することが可能です。最終的にチーターがBANされていれば問題は少ない。\n\nDAO は Deserializer を使って変換した上でとることのできる対策として\n\n* DAOの状態を変更するC#のDLLとしてビルドをしたものでチェックを行う  \n  これだと監査タイミングが任意になるだけで、理論的には全チェックが可能ですね\n* 機械学習で異常値の検出を行う(多段防御の一つとして)\n* 緩めな判定ロジックをしこむ(1日に可能なバトル実行回数だとか、課金量あたりでのアイテム増加量であるとか)\n\nDAOへの変更LogicをUnity非依存のアセンブリに記述することを徹底していたり、  重要なLogicの前後でのDAOさえ送信されていればどうにでもなる感じがします。\n","2019/12/28/10gbe":"自分へのクリスマスプレゼントとして購入しました。\n\n[BUFFALO の LXW-10G2/2G4](https://www.buffalo.jp/product/detail/lxw-10g2_2g4.html) を購入しました。10Gが2個と2.5Gが4個です、つまり10G出るのはPC2台だけ。タイトルに偽りあり。\n\n普通の10Gx8ポート買えばいいじゃない?、とも思いますが以下の点からこの選択に\n\n* 最終的にマトモなHubを買った時に、別の部屋おきhubとして使える小さなのが良い。\n* 当面接続するのはPC2台、NAS2台 + uplink\n* **安い**\n\n去年購入した MacMini は 10G に対応していますが、これ一台だと流石に意味がなさすぎるので、\n\n* QNAP QXG-10G1T (QNAP用)\n* ASUS XG-C100C (Windows用)\n\nを購入しました。両方現在は Marvell 傘下の Aquantia AQC107 採用モデルですね。QNAP は純正なので普通に動くし、Windows は公式ドライバですんなり動作。\n\nSMB + CrystalDiskmark で 10G 接続で 683MB/s、2.5G 接続で 296MB/s くらいでした。対象が NAS の SATA 接続の SSD なのでこんなもんでしょう。10G\\*3, 5G\\*2 くらいあれば十分ぽい。\n\n消費電力は...NASで5Wほど増加したので、全体で25Wほど増加した気がします。次は 10G(2.5G) に対応した 11ax (Wifi 6) の　Wifi router(access point) が欲しいな。\n","2020/02/11/ReverseProxyHttps":"chrome では WebXR Device API は https でないと有効にならないようなので、さっくりと試してみた。\n\n対象は [WebRTC Native Client Momo](https://github.com/shiguredo/momo) の提供する、http, WebSocket です。\n\n作業内容としては、証明書を取得する＋nginxでリバプロする、その二点だけです。\n\n# 証明書の取得\n\nみんな大好き [Let's encrypt](https://letsencrypt.org/ja/) です。\n\nいやもう大好きです。期限が短いから自動更新せざるを得ないし、自動更新作ってしまえば運用楽だし。無料だし。\n\ncertbot あたりが有名どころですが、lego を使いました。\n環境は閉じている方が楽なので Raspber Pi Zero で動作させます。\nそのため Mac からクロスコンパイルします。\n\n```sh\n$ git clone https://github.com/go-acme/lego.git\n$ cd lego\n$ export GOOS=linux\n$ export GOARCH=arm\n$ export GOARM=6\n$ make build\n```\n\nstrip するのが面倒なので、予め strip しておきましょう。\n\n```diff\n--- a/Makefile\n+++ b/Makefile\n@@ -23,7 +23,7 @@ clean:\n\n build: clean\n        @echo Version: $(VERSION)\n-       go build -v -ldflags '-X \"main.version=${VERSION}\"' -o ${BIN_OUTPUT} ${MAIN_DIRECTORY}\n+       go build -v -ldflags '-s -w -X \"main.version=${VERSION}\"' -o ${BIN_OUTPUT} ${MAIN_DIRECTORY}\n\n image:\n        @echo Version: $(VERSION)\n```\n\n今回は DNS サーバーは AWS/Route53 を使いました。\n\nクラウド破産しないように、Route53 用の IAM を作成しておきましょう。\n\n```sh\nexport AWS_ACCESS_KEY_ID=AXXXXX\nexport AWS_SECRET_ACCESS_KEY=XXXXX\nexport AWS_HOSTED_ZONE_ID=XXXXX\nexport AWS_REGION=us-east-1\n\n# 初期化\n./lego --accept-tos --path=./letsencrypt --email=\"mail@address\" --dns=\"route53\" --domains=\"*.foobar.com\" run\n# 更新\n./lego --accept-tos --path=./letsencrypt --email=\"mail@address\" --dns=\"route53\" --domains=\"*.foobar.com\" renew --days 30\n```\n\n実行に成功したら、上の例では `./letsencrypt/certificates/` 以下に証明書が保存されています。\n\n一般的には cron, CronJob で実行したりとか、コンテナの中に入れたりとか、renew したら Message 投げるとかすればいいんじゃないですかね。\n\n今回はロボ用なのであまり考えません。\n\n# nginx の設定\n\nみんな大好きかもしれない nginx でのリーバスプロキシです。wss も対応していてよかった。\n\n/etc/nginx/nginx.conf\n```\nevents {\n  worker_connections 768;\n}\n\nhttp {\n  upstream momo {\n    server localhost:8000;\n  }\n\n  map $http_upgrade $connection_upgrade {\n    default upgrade;\n    '' close;\n  }\n\n  server {\n    listen       443;\n    server_name  xxx.foobar.com;\n\n    ssl on;\n    ssl_certificate /xxx/letsencrypt/certificates/xxx.crt;\n    ssl_certificate_key /xxx/letsencrypt/certificates/xxx.key;\n\n    access_log /dev/null;\n    error_log /dev/null;\n\n    location /ws {\n      proxy_pass http://momo;\n      proxy_http_version 1.1;\n      proxy_set_header Upgrade $http_upgrade;\n      proxy_set_header Connection \"upgrade\";\n      proxy_read_timeout 86400;\n    }\n\n    location / {\n      proxy_pass http://momo;\n    }\n  }\n}\n```\n\n上で取得した証明書を使います。server_name に対応する Route53 のエントリは手動か自動かで作っておきます。\n\n# おわりに\n\n無事 Raspberry pi zero 上に https でアクセスできるようになりました！\n\nlego repository にある Dockerfile を少々改変し、QNAP/docker-compose 用の環境もついでに作りました。[こちら](https://github.com/Bugfire/lego-auto)\n"}