{"2017/03/11/InstallHexoAndThemes":"ふと思い立って、Github pages を使って Blog を作ってみた。\n環境は何でもよかったが、nodejs ベースの [Hexo](https://hexo.io/) を使ってみることにしました。\n\n# nvm/nodejs のインストール\n\nすでにインストールされていたnodejsが0.12だったので、ついでにnvmをインストール。\n\n```sh\n$ git clone git://github.com/creationix/nvm.git ~/.nvm\n```\n\n.profile に1行追加\n```sh\n$ echo 'if [[ -s ~/.nvm/nvm.sh ]] ; then source ~/.nvm/nvm.sh ; fi' >> ~/.bash_profile \n$ source ~/.bash_profile \n```\n\nバージョンは適当に選択\n```sh\n$ nvm --version\n0.33.1\n$ nvm ls-remote\n(いっぱい)\n$ nvm install v5.12.0\n$ node --version\nv5.12.0\n```\n\n# Hexo のインストール\n```sh\nnpm install --save hexo\n```\n\n## Blog の作成\n```sh\n$ ./node\\_modules/hexo/bin/hexo init blog\n$ cd blog\n$ npm install\n```\n\n## Theme の fork\n一応。github から landscape を fork しておく。\n\n## Theme の submodule 化\n```sh\n$ cd themes/\n$ git submodule add https://github.com/bugfire/hexo-theme-landscape.git landscape\n```\n","2017/03/17/AssetBundleCompress1":"# 目的\n\nAssetBundleはLZMAやLZ4で圧縮されますが、扱うデータの特性がわかっている場合はより特殊化した\n圧縮が期待できるのではないかと考えました。\n\n例えば目パチのようなアニメーションの画像データでは以下のようなアプローチがあります。\n\n- 目だけを上書きする透過画像を生成して上に乗せる。\n  透過面積が多い画像であれば標準のSpritePackerや [TexturePacker](https://www.codeandweb.com/texturepacker) で効率的なAtlas化が可能です。\n- 差分画像を生成する。例えば [宴](http://madnesslabo.net/utage/) のダイシング機能。\n\nしかし、今回は制約があり上の手法は使いません。\n\n# 前提\n\n制約は以下の通りです。\n\n- 使う側で特別なコードは一切書きたくない。\n- TextureでありSpriteではない。\n- 機種依存圧縮(PVRTC, ETC)を使いたい。\n- 透過なしで1パスで描画を行いたい。\n\nPVRTC, ETC のバイト列を生成し、Unity の Texture としてロードができればよいのですが、\nちょっとわからなかったので別の方法を試します。(\\*1)\n\n# 手法\n\nAssetBundle をただ圧縮し、インストール時に展開するというアプローチを試してみます。\n\nテクスチャ圧縮はGPUの機能的制約から固定長で同じサイズのテクスチャであれば、同じ座標のデータは\n同じブロックに存在します。したがって、局所性が高く、同一のピクセル構成部分であれば、同一のバイナリ構成になる可能性が高いと予想されます。\n(PVRTC は近辺のブロックも参照を行うので、影響範囲は少し大きめになりますが、距離に応じて影響は低くなります)\n\n(\\*1) のPVRTCからテクスチャ生成ができれば、AssetBundle 内で圧縮するアプローチを取ることができるのですが、Nativeでテクスチャを生成する以外の方法があれば、誰か教えてください...。\n\n# 問題点\n\n- 圧縮前はロスレス画像でなければならない。\n  見た目が同じでもLossyな圧縮を行なった結果、微妙に画像データが異なると困ります。\n- ストレージでの消費容量は無圧縮なので比較的大きい。\n- 複数のバリエーションをロードするとGPU側のメモリ消費は多い。\n- 暗号化を行えない。暗号化を先に行うと圧縮が難しい。\n  圧縮してから暗号化だと、ストレージでは圧縮を展開したデータになるため暗号化がかかっていない状態になります。\n\n[(2)](/#/blog/post/2017/03/17/AssetBundleCompress2)へ続く。\n","2017/03/17/AssetBundleCompress2":"# 実験\n\nデータはUnityChanをベースに、ImageMagickでAlphaチャネルを削除しました。\n```bash\n$ convert portrait_kohaku_02.png -background black -alpha remove portrait_kohaku_02a.png\n$ convert portrait_kohaku_01.png -background black -alpha remove portrait_kohaku_02b.png\n```\n\n画像サイズは2524x3189ですが、2048x2048, MipMap なしとして取り込みました。\nPVRTC/ETC1の4bppを使用で、2048x2048x4/8が2枚で4MBとなります。\n\n# スクリプト\n\nAssetBundle は以下の簡単なスクリプトで生成\n```cs\nusing System.Collections;\nusing System.Collections.Generic;\nusing UnityEngine;\nusing UnityEditor;\n\npublic static class AssetBundleCompressTest\n{\n    static string[] _assetNames = new string[2] {\n        \"Assets/AssetBundleTest/UnityChan/portrait_kohaku_01a.png\",\n        \"Assets/AssetBundleTest/UnityChan/portrait_kohaku_02a.png\",\n    };\n\n    static AssetBundleBuild[] CreateBuildMap (string mode, BuildTarget target)\n    {\n        AssetBundleBuild[] buildMap = new AssetBundleBuild[1];\n        buildMap [0].assetBundleName = string.Format (\"Test_{0}_{1}.unity3d\", mode, target);\n        buildMap [0].assetNames = _assetNames;\n        return buildMap;\n    }\n\n    [MenuItem (\"AssetBundlesCompress/RunTest\")]\n    static void BuildAssetBundles ()\n    {\n        var outputPath = \"AssetBundles\";\n\n        System.IO.Directory.CreateDirectory (outputPath);\n\n        //BuildTarget.Android,\n        //BuildTarget.iOS,\n        var target = EditorUserBuildSettings.activeBuildTarget;\n        BuildPipeline.BuildAssetBundles (\n            outputPath: outputPath,\n            builds: CreateBuildMap (\"RAW\", target),\n            assetBundleOptions: BuildAssetBundleOptions.UncompressedAssetBundle,\n            targetPlatform: target);\n        BuildPipeline.BuildAssetBundles (\n            outputPath: outputPath,\n            builds: CreateBuildMap (\"LZ4\", target),\n            assetBundleOptions: BuildAssetBundleOptions.ChunkBasedCompression,\n            targetPlatform: target);\n        BuildPipeline.BuildAssetBundles (\n            outputPath: outputPath,\n            builds: CreateBuildMap (\"LZMA\", target),\n            assetBundleOptions: BuildAssetBundleOptions.None,\n            targetPlatform: target);\n    }\n}\n```\n\n# 結果\n\n|方法|サイズ|\n|----|------|\n| RAW | 4198973 |\n| LZ4 | 876341 |\n| LZMA | 609787 |\n\n2x2048x2048x4/8は4194304なので、(4198973 - 4194304) = 4669byteがヘッダ等メタデータとなりますね。\n\nアーカイブの中身を見た感じ、未圧縮の形式では、ファイルの前にかならず、（文字列長) + (ファイル名)が、\n入るようなので、ここをファイルの区切りとして圧縮を試して見ます。\n\n[(3)](/#/blog/post/2017/03/19/AssetBundleCompress3)へ続く。\n","2017/03/19/AssetBundleCompress3":"# 圧縮の方針\n\n仮定\n- アーカイブ内に存在するファイルの内容は、同一オフセットには同一のデータが入ることが多い。\n\n# 実装\n\nアーカイブ全体からファイル名部分を検索するのには、有名な Boyer-Moore String Search アルゴリズムを使います。\nwiki にソースすらあるので、それを参考にしても良いですが、今回は StackOverflow の記事から使用させていただきました。\n\n参考:[Search longest pattern in byte array in C#](http://stackoverflow.com/questions/9889427/search-longest-pattern-in-byte-array-in-c-sharp/9890164#9890164)\n\nファイル名で区切られた領域をブロックとみなし、ファイル中の全ブロックと全ブロックを比べ、同じオフセットで同じデータ\nが入る部分を抽出し、出力は、データブロックと参照ブロックが並ぶ構成にしました。頭の悪い辞書圧縮という感じです。\n\n正確にデータ部分が抽出できれば、PVRTC/ETC1ともに8byteが1blockなので、それを利用して、オフセットによらず圧縮テクスチャ特化型辞書圧縮もできそうですが、手間をかけない方針なのでやりません。\n\n参考:[Disunity on github](https://github.com/ata4/disunity)\n\n# 結果\n\n|方法|サイズ|\n|----|------|\n| RAW | 4198973 |\n| LZ4 | 876341 |\n| LZMA | 609787 |\n| 圧縮 | 2381911 |\n\n大部分が同じデータなのでだいたい半分にはなりましたが、通常の圧縮をしていないのでまだまだ大きいですね。\n\n[(4)](/#/blog/post/2017/03/19/AssetBundleCompress4)へ続く。\n","2017/03/19/AssetBundleCompress4":"# 圧縮\n\n下段として通常の圧縮を試してみます。その前に、先人の知恵を見て見ましょう。\n\n参考:[.NET Compression Libraries Benchmark](https://ianqvist.blogspot.jp/2014/12/net-compression-libraries-benchmark.html)\n\n何も考えずに.NETのDeflateと、性能が良さそうなLZMAを試して見ることにします。\n\nLZMAはPublicDomainの7Zip SDKを使用します。\n\n# 結果\n\n|方法|サイズ|\n|----|------|\n| RAW | 4198973 |\n| LZ4 | 876341 |\n| LZMA | 609787 |\n| 圧縮 | 2381911 |\n| 二段圧縮(.NET) | 409940 |\n| 二段圧縮(LZMA) | 318962 |\n\nようやく、素のLZMAの半分くらいになりました。DeflateとLZMAは、速度とサイズのトレードオフでしょうか。\n\nサンプルソースは、 [https://github.com/Bugfire/test_assetbundlecompress](https://github.com/Bugfire/test_assetbundlecompress) に置いておきました。\n\n# 追記\n\n[2016年のOSS圧縮ツール選択カタログ](https://qiita.com/nishemon/items/818cc64dc2f8577edd87) を読んだら、zstdのC#版が欲しくなってきました。native wrapperは存在しましたが、なんとなく。\n","2017/05/06/QnapFfmpeg":"家で家族の動画を共有している QNAP / DLNA が最近動いていないのでメンテをしました。\n\n- TwonkyServer がメンテされていないみたいなので、標準の DLNA Server に置き換えました。\n- PS4 から見に行くと反応が遅いですが、一応動いていますね。\n- もともと、MTS がうまく再生できていなかったのは、やっぱりうまくいかない。\n- トランスコード設定をしてみるが、やっぱりうまくいかない。\n- ログをみると変換に失敗しているようだ。\n\n昔は、自分で QNAP 上で ffmpeg を実行して再生可能にしていたので、思い出しつつ実行してみる。  \n\n- 過去のスクリプトではやっぱりうまくいかない。\n- コマンドラインオプションが違うようだ。ffmpeg のバージョンが違うかな？\n- ググってみると複数の ffmpeg が入っているようだ。確かに。\n- 新しい方でもやっぱりこける。ググってみるとライセンス上の問題で AC3 を外しているようだ。\n\nしょうがないので自前ビルドしてみる。\n\n- ipkg がない...。これも紆余曲折あって App Center から入らないようだ。\n- [こちらから](https://github.com/Entware-ng/Entware-ng/wiki/Install-on-QNAP-NAS)インストール\n- ```/opt/bin/opkg install ffmpeg```\n\nなんとか動作。\n","2017/05/16/RayProfiler":"簡単なデバッグ用スクリーンインジケータを作りました。\nゲーム開発でよく見る奴です。\n\n車輪の再発明というか、標準の Profiler でよくね？と思いますが、私もだいたい同意です。\n\n![RayProfiler](/blog/images/RayProfiler.png \"RayProfiler\")\n\n- 上の白い四角がTargetFPSの範囲になります。グラフがはみ出すのは処理が間に合っていないときです。\n- 赤がRender、グレーは1フレームの時間です。Editor 上のスクリーンショットなので TargetFPS とグレーが一致していませんね。\nPhysics, Update, LateUpdate, Animation 等の処理別に処理時間を計測していますが、Render 以外は目立ちません。\n- 下が過去60フレームの1フレームの処理時間/1フレームの時間のグラフです。\n- GCがあったフレームはグラフ上で赤/黄で目立つように表現されます。\n\n## 特徴\n- リリースビルドでも動く(むしろ、止めたければどうにかいじってください)\n- 動的なメモリ割り当て無し(例外あり、後述)\n- スクリーンに描画を行うので、実機で確認可能\n\n## 動的なメモリ割り当てなし\nプロファイル、描画等で動的なメモリ割り当ては行なっていません。固定バッファでやりくりしています。\n\n例外は、 `yield WaitForEndOfFrame` を行なっている部分で、Unity側の `MoveNext ()` で毎フレーム16byte確保されます。\n誰か防ぐ方法教えてください。\n\n## RayString\n低機能なStringモドキです。使い方は例を見ればわかると思います。\n```\nvar r = new RayString(100);\nr.AddStr (\"Foo\").AddInt (10).AddStr (\"Bar\").AddFloat (0.5f, 0, 1);\nAssert.AreEqual(r.ToString (), \"Foo10Bar0.5\");\n```\n上の例では、`ToString ()`でnew stringされていますが、`char[] Buffer`を参照することで動的メモリ割り当て無しで中身が取り出せます。\n\n実装上の都合で(floatの内部表現が面倒なので)、AddFloat の精度は低いです。float の持つ精度を超える小数部の桁数を指定した場合、\nC# のライブラリでは0でフィルされますが、このAPIでは精度以上の部分はゴミが入ります。\n\nバッファが溢れそうなときは拡張を行うので、このときは動的メモリ割り当てを行います。\n\n## RayCanvas\nデバッグ用簡易Canvasです。文字列と矩形しか表示しません。\nMesh 用のデータを静的に持っておくことで、動的割り当てを回避する実装になっています。\nデータサイズは静的になりますが、表示内容が少なくても多くてもメモリ消費も描画コストもかかります。\n\n## 参照\nパッケージとソースは[github](https://github.com/Bugfire/snippets/tree/master/unity/RayStorm)にあります。\n\nUnity5.3, 5.4, 5.5. 5,6でパッケージを作りましたが(疲れました)、ソースは同一です。サンプルprefabをそれぞれのバージョンで生成しただけです。\n","2017/10/08/diskchecker":"ドライブレコーダー用にMicroSDを何枚か買いました。SDカード系って偽物とかありますよね。自分は信頼できる店でしか買わないのでひっかかったこととかないつもりですが...。\n\nチェックするツールもWindows用でいくつか検索で見つけることができますが、色々と面倒なので低機能なものを使ってみました。\n\n- node.jsで200行未満\n- ディスクが一杯になるまで指定ディレクトリに再現可能な乱数系列の256MBのファイルを作成し続ける\n- ディスクが一杯になったら、作成したファイルを検証する\n- ついでに読み込み・書き込み速度を測る\n\n低レベルで検査しているわけではないので、全エリアはチェックしていません(256MB未満の残り領域、アライメント部分、ディレクトリ情報等)。デバイスファイルを使えばできますが、オペミス怖いしそこまでやらなくてもいいと思いましたのでこのような実装にしました。\n\n[https://github.com/Bugfire/diskchecker.git](https://github.com/Bugfire/diskchecker.git) にあります。\n\n","2018/03/19/WakeOnLan":"PC を定期的に起動・終了したく、試しました。\n\n## 指定時間で停止\n\n```bash\n$ sudo crontab -e\nMM HH * * * /sbin/shutdown -h now\n```\n\nまあ、普通ですね。歴史的に(?) localtime での時間設定らしいので、気をつける。\n\n起動時にしか localtime をチェックしないので、起動後に localtime を変更する場合は、 cron を再起動しておく。\n\n```\nsudo service cron restart\n```\n\n## 指定時間で起動\n\nWake On Lan の magic packet を投げる方法はいくつもあると思いますが、nodejs に慣れているのでそれを選びます。\n\n### 依存ライブラリのインストール\n\n```bash\nnpm init\nnpm install --local --save wake_on_lan cron forever\n```\n\n- wake\\_on\\_lan 名前通り\n- cron 時間で指定して実行\n- forever おてがるデーモン化\n\n### テスト\n\nひとまず実行してみる。\n\n```javascript\nconst wol = require('wake_on_lan');\nwol.wake('xx:xx:xx:xx:xx:xx');\n```\n\n起動する。楽だ。LAN が複数ポートある場合は、一つ目にしか飛ばないのか起動しなかったのでオプションをつける。\n\n```javascript\nwol.wake(mac, { address : '192.168.xx.255' });\n```\n\n動かない場合は `sudo tcpdump -nX udp and port 9` 等で対象と同じネットワークから見てみる。\n\n### 結果\n\n最終的には、設定を外出ししてこんな感じに。\n\nソースファイル\n```javascript:wol.js\n'use strict';\n\nconst wol = require('wake_on_lan');\nconst config = require('./config.js');\n\nfunction kick() {\n    config.hosts.forEach(host => {\n        wol.wake(host, config.wol);\n    });\n};\n\nconst CronJob = require('cron').CronJob;\nnew CronJob(config.schedule, kick, null, true, config.timezone);\n```\n\n\n\n設定ファイル\n```javascript:config.js\nmodule.exports = {\n    timezone : 'Asia/Tokyo',\n    schedule : 'MM HH * * *',\n    hosts : [\n        'xx:xx:xx:xx:xx:xx',\n    ],\n    wol : {\n        address : '192.168.xx.255',\n        num_packets : 10,\n        interval : 500,\n    },\n};\n```\n\n### デーモン化\n\n- 起動 `./node_modules/forever/bin/forever start ./wol.js`\n- 終了 `./node_modules/forever/bin/forever stop ./wol.js`\n- 確認 `./node_modules/forever/bin/forever list`\n\n長いパスが嫌な子はパスを通すか wrapper を作るか、global にインストールなぞ。\n\n## 参照\n\n多少コードは違いますが、ソースは[github](https://github.com/Bugfire/wake_on_lan.git)にもあります。\nこちらはDockerhubでビルドもしていてコンテナ用になっています。\n","2019/02/28/VRMViewer1":"ロボスタの勉強会に出席してみて、VRM(というかUniVRM)は気軽だな、と再認識したので試してみた。\n\nせっかくなので、WebGL ビルドで。\n\nhttps://bugfire.dev/VRMViewer/index.html\n","2019/09/27/React":"長いお休みをいただいているので、練習がてら、このサイト(Bugfire.dev)を React で SPA/PWA 化しました。\n\nPage は gh-pages でホストをして、Blog は Markdown にして、index と記事を json でホストして取りに行くようにしました。\n\nRedux/Flux 的なことは Unity や Vue.js で少しかじりましたが、今回は端折りました。\nというか色々端折っても三日かかりました、難しい。\n\nTODO\n\n- [ ] Year/Month/Tag で絞り込むUI\n- [ ] Android でアイコンが丸くならない、困った。\n\n  \"purpose\": \"maskable\" で良いとの記事を見たが動かない。\n  十分透過な画像を食わせると良いとは読んだけど、それやると iOS が変になりそう。\n- [ ] Markdown (GFM)\n- [x] Markdown (Code highlight)\n- [ ] atom.xml, sitemap.xml\n\n","2019/09/30/DockerComposeOnQnap":"# ContainerStation\n\nQNAP の ContainerStation をとても便利に使っていたのですが、Deploy のたびに設定 (UIからVolume等) をしたりとか、複数の Container が協調するのがめんどいというか、DockerCompose したいよなあ、と思って VPS を借りてみたりしましてました。\n\nDockerCompose 対応してる、ということに、最近ようやく気が付きました(最初からあった?)。\n\n## DockerCompose == APP\n\nQNAP 用語的には、docker-compose は **APP** ということみたいです。\n\nDocker 社の作っている app plugin とは別物っぽいです\n\n**APP** は二通りの作成方法があるようです。\n\n- ライブラリ(初期設定なら https://github.com/qnap-dev/container-apps/tree/2.0) をつかう\n  templte/*/wizard でメニュー設定と、docker-compose.yml の項目への binding が定義できるようだ。\n- 自分で設定する(**作成**の所の**アプリケーションの作成ボタン**から docker-compose.yml を編集して追加できます)\n  docker-compose.yml に即値で書いていく。\n\n自分は後者を使いました。設定項目が全て手の中にあるのでバックアップ・履歴管理も楽だし。(docker-compose.qnap.yml で commit しています、詳細な設定・秘密情報は Volume に置く方針です)\n\n注意としては、build エントリがあると失敗するので、消しておきます。なければ image を自動的にダウンロードして実行します。\n\n## image の更新\n\nなお、概要タブの Container/APP 一覧から、編集ボタンを押すと既存の **APP** の yml の編集ができ、**適用** すると自動的に更新されます。\n\ntag を :latest にした場合は **適用** を実行したところで、既存の latest を更新してくれないので、image を削除する必要があります。参照されていると削除できないので、面倒です。普通に versioning しましょう。\n","2019/09/30/Qnap20190930":"## Refactoring\n\n- Docker/JavaScript で作ったものを DockerCompose/TypeScript でリファクタリング\n- npm package の update, http から axios への書き換え\n- マルチステージビルドを使って image の削減\n- 共通化部分を切り出し\n- syslog に投げる\n\nみたいなことをしていました。\n\n## Nature Remo\n\n特に意味もなく Raspberry pi 2B で部屋の温度をとって DB に放り込んでいましたが、そんなこんなで NAS 側に写しました。温度は Nature Remo の方の API に切り替えて、湿度と照度\bが取得できるようになったので、毎分記録するようにしました。\n\n地味に unbound が動いていた (dns blacklist を作っていた) のに気が付いていなくて、突然名前が引けなくなってびっくりしたりした。\n\nuptime が 1000 日以上だったので、トラブルもなく安定してよく動いていたな、と思いました。(Security update は置いておいて)\n\n## EOL and hardwares\n\n過去の構成は:\n\n- TS-259Pro - Surveillance Station & DB & Backup\n- TS-651 - Docker & FileSharing\n\n購入してから6年くらいの TS-269Pro の EOL が近づいて来ていたので、TS-453Be を購入しました。\n\n今の構成は:\n\n- TS-651 - Surveillance Station & DB & Backup\n- TS-453Be - Docker & FileSharing\n\nTS-453Be を SSDx2 の構成にしたら、11~13W くらいの電力消費におちつきました。CPU を全然回していないとはいえ、最高ですね?\n\nTS-651 は SSDx2 HDDx2 で 37W くらいです。SSDで電気代が月500円安くなったとして、5年で3万円、過去の書き込みレートだと 60G/day くらいだったので、1年で21TBW、5年なら100TBW、TBW的にはいけそうですが、まだまだ容量単価がつらい。\n(TimeMachine 等の Backup も兼ねているので、あまり容量を削れない)\n\nSurveillance Station の課金が別 NAS に移行できないので、QVR Pro を試しているのですが重いねコレ...。\n"}